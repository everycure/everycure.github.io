<p>
    The ROADMAP team did extensive data cleaning and analysis of the survey data, primarily using R studio<sup><a
            href="#fn8" id="ref8">8</a></sup> packages: tidyverse,<sup><a href="#fn9" id="ref9">9</a></sup>
    stringr,<sup><a href="#fn10" id="ref10">10</a></sup> dplyr,<sup><a href="#fn11" id="ref11">11</a></sup> and
    googlesheets4.<sup><a href="#fn12" id="ref12">12</a></sup>
</p>
<h3>
    Inclusion criteria implementation & data cleaning
</h3>
<p>
    The data cleaning process consisted of five steps, which were executed concurrently:
</p>
<ol>
    <li>
        Implementing inclusion criteria
    </li>
    <li>
        Deduplication and merging
    </li>
    <li>
        Name cleaning and translations
    </li>
    <li>
        (Re-)classification and categorization
    </li>
    <li>
        Data changes, corrections, and updates
    </li>
</ol>
<h4>
    1. Implementing inclusion criteria
</h4>
<p>
    Survey entries were removed from the final dataset for several reasons, including:
</p>
<ul>
    <li>
        Organization was not a registered 501c3 nonprofit (<b>3</b>)
    </li>
    <li>
        Organization does not support a rare disease (<b>2</b>)
    </li>
    <li>
        Organization did not meet US location criteria (<b>155</b>)
    </li>
    <li>
        Data submitted to Qualtrics after completion deadline (<b>6</b>)
    </li>
    <li>
        Progress less than 10% survey completion (<b>399</b>)
    </li>
    <li>
        Did not consent / did not answer consent question (<b>572</b>)
    </li>
    <li>
        Did not answer any questions associated with stakeholder sections (<b>53</b>)
    </li>
    <li>
        Data was a duplicate marked for removal (see “Deduplication and merging” for details) (<b>10</b>, not including RDNPs)
    </li>
</ul>
<p>
    We applied each inclusion/exclusion criteria in the order presented here and updated the numbers of removals that
    were made after each step was applied to the dataset. This means that survey entries from later steps (e.g., “Didn’t
    meet US location criteria”) do
    <b>not</b>
    include entries from earlier steps (e.g., progress less than 10%).
</p>
<p>
    In total,<b>1,324</b> entries (out of an original <b>1,929</b>) were removed due to not meeting inclusion criteria leaving <b>605</b> entries that qualified to remain in the final dataset.
</p>
<h4>
    2. Deduplication and merging
</h4>
<h5>Deduplication procedure</h5>
<p>
    In some cases, the same individual completed the survey twice. To identify these cases, we looked for duplicate
    email addresses and/or IP addresses, as there was no other identifiable data collected via the survey. Then, we
    identified mismatches between their survey responses, if any, and manually reconciled these differences by combining
    information to make entries as complete as possible. We also resolved any contradictions and inconsistencies between
    entries that we identified.
</p>
<p>
    There were some cases where multiple rare disease nonprofit representatives completed the survey for the same
    organization, causing this deduplication process to be more complex. To identify these cases, we looked for rare
    disease nonprofit name matches among those who opted into the associated section of the survey. Then, we compared
    the completion rates on these entries; entries with higher progress were automatically selected over entries with
    lower progress. In cases where the completion rate of each entry was equal (e.g., 100%), we compared the titles of
    each representative. In cases where one entry’s representative had seniority (founder, CEO, executive director), we
    kept that entry. In a select handful of cases where both the progress and participant hierarchical standing were
    equal, we followed the same process described prior and manually reconciled any differences identified.
</p>
<figure class=" py-4">
    <table class="table">
        <thead class="table-dark">
            <tr>
                <th scope="col">Type of duplicate</th>
                <th scope="col">Variables of interest</th>
                <th scope="col">Identification method</th>
                <th scope="col">Deduplication process</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td scope="row">
                    Cases where the same individual completed the survey twice
                </td>
                <td>
                    Question Q13 (email address) + IP addresses
                </td>
                <td>
                    Look for duplicate email and/or IP addresses.
                </td>
                <td>
                    Keep data that is the same between the multiple entries; reconcile differences between entries with
                    contradicting information.
                </td>
            </tr>
            <tr>
                <td scope="row">
                    Cases where representatives from the same rare disease nonprofit completed the rare disease
                    nonprofit stakeholder section of the ROADMAP survey
                </td>
                <td>
                    Question Q10 (stakeholder survey selection) + question Q301 (rare disease nonprofit name) + question
                    Q17 (title) + Progress
                </td>
                <td>
                    Look for rare disease nonprofit name matches among those who opted into the rare disease nonprofit
                    stakeholder section of the survey.
                </td>
                <td>
                    If one entry is more complete than another, keep the entry that is more complete.
                    <br>
                    <br>
                    If completion rate is equal, but one of the entries was completed by a more senior representative
                    founder, CEO, executive director);
                    <br>
                    <br>
                    Keep data that is the same between the multiple entries; reconcile differences between entries with
                    contradicting information.
                </td>
            </tr>
        </tbody>
    </table>
    <figcaption>
        Overview of the deduplication process
    </figcaption>
</figure>
<h5>Merging procedure</h5>
<p>
    The merging procedure involved combining the data from the follow up survey with the original survey data as
    described in a prior section. We began with
    <b>200</b>
    follow-up survey entries, and we successfully matched
    <b>191</b>
    of these entries to their corresponding ROADMAP survey entries. To do so, we compared the IP and email addresses
    from the original and follow-up surveys, and we merged entries where matches were found. We then isolated the data
    on which drugs patients from each survey reported taking. We compared groupings of drugs, and combined entries where
    unique matching pairs were found. Ultimately, we discarded 9 follow-up survey entries that could not be matched to
    the original survey data via IP/email addresses or drug names.
</p>
<p>
    It should be noted that while
    <b>191</b>
    successful matches were made, only
    <b>156</b>
    entries were ultimately combined with their original ROADMAP survey data. This is because
    <b>35</b>
    of the follow-up survey entries were from respondents whose entries were removed from the dataset during the
    inclusion filtering process outlined in the
    <i>“Filtering based on inclusion criteria”</i>
    and
    <i>“Deduplication and merging”</i>
    sections.
</p>
<h4>
    3. Name cleaning and translations
</h4>
<h5>
    Name cleaning
</h5>
<p>
    We reviewed and cleaned all manually-inputted job titles, specialties, organization names, disease names, and drug
    names. While each process varied in its scale (whereas there were only a few unique specialties to clean, there were
    hundreds of drug names to clean) and scope (e.g., drug/disease name cleaning efforts were extended to additional
    projects), the actual cleaning process was nearly identical across each cleaning activity.
</p>
<p>
    Each step in the cleaning process required isolating unique names, and then developing a “key-pair” dictionary with
    a column for the original name, and a column for its (optional) replacement. Members of the ROADMAP team, including
    volunteers, would then review the original names, identify inaccuracies and inconsistencies, and generate a final
    list of accurate replacements. In some cases, data was marked for removal (e.g., if a disease listed was not rare,
    or a drug listed as FDA-approved turned out to not be FDA-approved). Any use of brand-name drugs was replaced with
    their generic name, and the names of pharmaceutical salts were removed as well. Acronyms were avoided whenever
    possible. Each dictionary was imported into R and used to clean the corresponding survey data.
</p>
<figure>
    <table class="table">
        <thead class="table-dark">
            <tr>
                <th scope="col">Original drug name</th>
                <th scope="col">Replacement drug name</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td scope="row">Tylenol</td>
                <td>Acetaminophen</td>
            </tr>
            <tr>
                <td scope="row">Tyelnol</td>
                <td>Acetaminophen</td>
            </tr>
            <tr>
                <td scope="row">Acetaminophen</td>
                <td>Acetaminophen</td>
            </tr>
            <tr>
                <td scope="row">Acetaminophen (500mg)</td>
                <td>Acetaminophen</td>
            </tr>
            <tr>
                <td scope="row">I can’t remember</td>
                <td>REMOVE</td>
            </tr>
        </tbody>
    </table>
    <figcaption>
        Example key-pair dictionary
    </figcaption>
</figure>
<h5>Translations</h5>
<p>
    Two participants who met our inclusion criteria completed the Spanish-language version of the survey. To ensure that
    their data would be represented in our analysis, we translated their survey responses into English. In cases where
    translations of participant-entered text were required, two Spanish speakers (one native speaker, and one non-native
    speaker) reviewed each translation for accuracy.
</p>
<h4>
    4. (Re-)classification and categorization
</h4>
<p>
    For the purposes of analysis and visualization, we created new variables that were used to classify/categorize
    existing data. Examples include, but are not limited to the following:
</p>
<ul>
    <li>
        Creating new categories for existing questions based on responses provided in the “other” sections
    </li>
    <li>
        Classifying disease names
    </li>
    <li>
        Classifying drug repurposing stages, status, and progress
    </li>
    <li>
        Classifying job titles
    </li>
    <li>
        Creating new variables (e.g., indicating whether drugs are FDA-approved based on human review; indicating
        whether an organization is focused on multiple diseases)
    </li>
</ul>
<p>
    Additionally, some response categories were renamed, merged, and/or removed based on team expertise and consensus.
</p>
<h4>
    5. Data changes, corrections, and updates
</h4>
<p>
    We have made changes, corrections, and updates to our data on an ongoing, case-by-case basis. While we made minor
    updates to our patient, loved one, researcher, and physician data, most of our updates have been made to our rare
    disease nonprofit survey data. For example, in the rare case when a drug status change was identified among our list
    of 147 rare disease nonprofits since (e.g., a new drug being targeted for repurposing; a drug receiving FDA
    approval), we updated all survey question data corresponding to that drug. In a few instances where participant
    clarification was required to resolve inconsistencies, we reached out directly to rare disease nonprofits for their
    assistance using the email addresses that they provided. In some of these cases - such as when the participants
    directly let us know that the drug was listed in error - we would remove all data related to that drug from our
    dataset. Except for these major changes, we did not make updates based on any other status updates that were
    discovered throughout the research and interview process, and the dataset provides a snapshot of the state of drug
    repurposing as of survey date completion and some of the data may be or soon will be outdated.
</p>
<h3>
    Data analysis
</h3>
<p>
    The survey data analysis process mostly focused on:
</p>
<ol>
    <li>
        Descriptive statistics
    </li>
    <li>
        Categorization
    </li>
    <li>
        Visualization
    </li>
</ol>
<h4>
    1. Descriptive statistics
</h4>
<p>
    We performed descriptive statistics analysis to report basic quantitative statistical data about the ROADMAP survey.
    Examples include frequencies, measures of central tendency, and correlations. Generally speaking, we summarized raw
    survey data in our descriptive analysis. In a handful of cases, however, we developed new variables and/or created
    aggregations of variables for the purposes of analysis. All descriptive statistics have been calculated using R and
    R studio(8). The overarching goal of this descriptive analysis has been to characterize the rare disease nonprofits
    who participated in the ROADMAP survey (their typologies; outcomes and endpoints; characteristics; resources; etc.).
    Below, we review the general process that we followed to visualize, report, and share our findings from the ROADMAP
    survey. We also explore in more detail how we used the descriptive data that we collected to answer essential
    questions about the drug repurposing process and the progress of RDNPs in their drug repurposing journeys.
</p>
<p>
    Most of the descriptive data that we generated were presented through bar charts, pie charts, and word clouds, among
    other visualizations. We created rough drafts of these visualizations using R. We generally focused on showcasing
    aggregated frequencies of survey options. In certain cases, multiple questions were combined and aggregated; in
    other cases, individual questions were broken down into multiple charts. Once we narrowed our selection of
    visualizations and created summaries of our findings, we built out a set of interactive web pages showcasing these
    final visualizations and the insights gathered from them. The ROADMAP Project’s Survey Insights, available to
    explore
    <a href="survey-insights-welcome.html" target="_blank">here</a>
    , are one of the ways that rare disease nonprofit organizations, as well as any other interested stakeholders, can
    explore our dataset and use it to inform further research or generate new insights.
</p>
<figure class=" py-4">
    <img class="img-fluid shadow-2-strong" src="{{site.baseurl}}/assets/images/about/survey-insights.png">
    <figcaption>
        Snapshot of the ROADMAP Project’s Survey Insights
    </figcaption>
</figure>
<h5>
    Drug Repurposing
</h5>
<p>
    In order to analyze the progress of rare disease nonprofits in the drug repurposing process, we categorized the
    various steps involved in this process into stages. The stages that we developed were based on several questions
    from the survey and included:
</p>
<ul>
    <li>
            <b>Early stage</b>: Securing funding, trying to secure researcher interest to pursue, testing existing drugs
            in mouse or other animal models, patient data collection
    </li>
    <li>
            <b>Clinical trials</b>: Recruiting patients for clinical trials, executing clinical trials stages I, II, III
    </li>
    <li>
            <b>Late stage</b>: Analyzing clinical trial data, submitting for FDA approval, receiving FDA Breakthrough
            designation
    </li>
</ul>
<p>
    Additionally, we worked to develop several success outcome categories, which would include more than just official
    FDA approval and provide alternative ways to conceptualize and measure drug repurposing success for rare diseases:
</p>
<ul>
    <li>
            <b>FDA approval</b>
    <li>
            <b>Off-label use, with some subjective measure of benefit</b> (<i>Drug to provide significant reduction in
                symptoms, improvement in quality of life, increase life expectancy/decrease in mortality, cure of
                disease, prevention of relapse</i>)
    </li>
    <li>
        <b>Off-label use, without any subjective measure of benefit</b>
    </li>
    <li>
       <b>Unsuccessful</b> (<i>project abandoned or FDA approval denied</i>)
    </li>
    </p>
    </li>
</ul>
<p>
    Once we had identified and classified these stages, we began to formulate specific questions about our data. While
    our general interest was to assess the relationship between organizational characteristics, drug identification
    methods, and stage(s) of progress, specific research questions included (but were not limited to):
</p>
<ul>
    <li>
        How many organizations had how many drugs in what stages currently?
    </li>
    <li>
        How each drug was identified and what stage is it in currently?
    </li>
    <li>
        How/Whether each organization's characteristics are related to the drug identification method used?
    </li>
    <li>
        How/Whether the drug identification method is related to the various types of “success” endpoints?
    </li>
</ul>
<p>
    To answer these questions, we developed cross-tabulations of our data, which involved breaking the data into
    subgroups in order to look for patterns, trends, or other noteworthy observations. To be clear, this was a purely
    descriptive undertaking: we did not perform any kind of inferential or predictive statistics using our data.
    Instead, we focused on reporting raw frequencies, proportions, and percentages, and we used these numbers to help
    describe, characterize, and summarize our drug repurposing data, as well as answer the specific research questions
    outlined above.
</p>
<p>
    One challenge that we had to address in developing cross-tabulations was that we were asking questions about two
    different units of analysis: in one case, drugs being repurposed (
    <b>94</b>
    total); in another case, the organizations involved in drug repurposing (
    <b>40</b>
    total). To address this, we made two separate sets of cross-tabulations, each taking a different unit of analysis.
    Both sets of cross-tabulations included the aforementioned list of drug repurposing stages (early, clinical trials,
    late, etc.). When taking repurposed drugs as our unit of analysis, we summarized this information on a per-drug
    basis. When taking organizations as our unit of analysis, we summarized this information on a per-organization
    basis. This required “flattening” the data of organizations repurposing multiple drugs into single yes/no responses.
    We, therefore, decided that when looking at this data on an organizational level, any “yes” responses from an
    organization’s survey data would overwrite any “no” responses, as our goal here was to understand whether they had
    reached a given stage at any point; we relied on the drug repurposing cross-tabulations for more fine-grained
    information about how many specific drug repurposing projects reached each stage.
</p>
<p>
    When taking organizations as our unit of analysis, we compared our stage data with our data on organizational
    characteristics/resources. When taking repurposed drugs as our unit of analysis, we compared our data on stages with
    our data on drug identification methods. In the table below, drug repurposing stages are represented in the rows,
    while drug identification methods are represented in the columns. Each stage / drug identification method is broken
    into a “yes” and “no” subcategory, where “yes” indicates that a survey-taker explicitly answered “yes” to the
    corresponding survey question(s), and vice versa for “no” selections. We filtered out cases where the question was
    left completely blank (instead of inferring, for example, that this indicates a “no”), meaning that our marginal
    totals (the sum of all cells in a given 2x2 contingency table) do not always neatly sum to 94/40.
</p>
<p>
    Each set of 4 gray highlighted squares in the snapshot below represents a single 2x2 contingency table that we could
    study individually and/or compare against other 2x2 contingency tables.
</p>
<figure class=" py-4">
    <img class=" shadow-2-strong" style = "width: 100%; height: auto;" src="{{site.baseurl}}/assets/images/about/contingency-full.png">
    <figcaption>
        Snapshot of the contingency table looking at drug identification methods and where the drug is currently
    </figcaption>
</figure>
<p>
    For a concrete example of how the above contingency table is read, we can “zoom in” on the top-left 2x2 contingency
    table, which displays information about two subgroups of drugs being repurposed: those in the “early” stage of drug
    repurposing and those that relied on “medical data” in the drug identification process. Looking at the below table
    tells us the following information about the relationship between this specific stage and drug identification
    method:
</p>
<ul>
    <li>
        <b>6</b>
        repurposed drugs are currently in the early stage of drug repurposing and were identified using medical data
    </li>
    <li>
        <b>19</b>
        repurposed drugs are currently in the early stage of repurposing but were
        <i>not</i>
        identified using medical data
    </li>
    <li>
        <b>14</b>
        repurposed drugs were identified using medical data, but are
        <i>not</i>
        in the early stage of repurposing
    </li>
    <li>
        <b>34</b>
        repurposed drugs were
        <i>not</i>
        identified using medical data, and are
        <i>not</i>
        in the early stage of repurposing
    </li>
</ul>
<figure class=" py-4">
    <img class="img-fluid shadow-2-strong" style = "max-height: 300px!important; width: auto;" src="{{site.baseurl}}/assets/images/about/contingency-zoom.png">
    <figcaption>
        Example of a 2x2 contingency table (comparing drug repurposing stages with drug identification data)
    </figcaption>
</figure>
<h4>
    2. Categorization
</h4>
<p>
    One of the important outcomes of the ROADMAP project was a comprehensive understanding of all the “menu” items in
    the drug repurposing process, namely all the steps involved and all the options that a researcher can pursue or a
    representative of a rare disease nonprofit can support. Based on our experience and expertise, the ROADMAP team
    implemented a preliminary list of options in the survey, but via user feedback from various stakeholders, we were
    able to build out a more detailed breakdown of both the stages involved in the drug repurposing process as well as
    the options that are available for selection within each step. This categorization was done through an ongoing
    manual, collaborative visualization exercise using the tool
    <a href="https://miro.com/" target="_blank">MIRO</a>
    , which allows for mind mapping, timeline building and other visualization techniques in an infinite, collaborative
    workspace. We also utilized this approach to merge the interview insights with the existing survey data, which we
    will describe in a later section.
</p>
<figure class=" py-4">
    <img class=" shadow-2-strong" style = "width: 100%; height: 100% !important;" src="{{site.baseurl}}/assets/images/about/miro.png">
    <figcaption>
        Illustration of the categorization processes done in MIRO
    </figcaption>
</figure>
<h4>
    3. Network Visualization
</h4>
<p>
    One of the sections of the rare disease nonprofit organization representative survey focused exclusively on their
    collaboration network. In this section, the rare disease nonprofit organization representatives were asked to list
    their top collaborator organizations by name, and then specify what kind of collaboration activities they were
    engaged in with them. From this data, we also built a network dataset of nodes (organizations) and edges (the
    relationships between organizations). We visualized this network using a tool called Gephi.<sup><a href="#fn13"
            id="ref13">13</a></sup> This allowed us to gain a better understanding of the types of relationships going
    on between different rare disease nonprofit organizations, as well as their external links to research institutions,
    pharmaceutical companies and government organizations.
</p>